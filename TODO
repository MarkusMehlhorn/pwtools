base.py
-------
* Re-think the whole implementation of FlexibleGetters. I think all of this can
  be done using lazy evaluation, i.e. decorate getters in derived classed with
  something like "@lazyproperty". Then the actual calculation is done only
  once, if a attr is accessed (i.e. struct.cell). Currently we do that with
  calls to check_set_attr() in each getter. Some ideas: 
  http://stackoverflow.com/questions/3012421/python-lazy-property-decorator
  Then, FlexibleGetters can be removed completely!

parse.py
--------
* Many classes still call the base classes' __init__ explitely. We get unbound
  method errors in interactive Ipython sometimes if we reload modules. We need
  to use use super() instead. But that only calls *one* __init__, namely the
  one from the major base class::

    class C(B,A):
        pass
    # calls only B.__init__, not A.__init__    
    c=C()
  
  In some classes, we call __init__'s of two base classes and cannot use
  super() then? Is this bad design?
* Speed: We did some profiling using kernprof.py on Cp2kMDOutputFile, which
  uses np.fromstring(backtick(cmd)).reshape(...). We found that the Python
  overhead for this command compared to executing all the grep/sed/awk stuff in
  `cmd` directly in the shell is small (about 10% top). So, the rest of
  slowdown comes from stuff which we do in pure Python with the parsed arrays
  (esp. in Trajectory, I guess, which calls crys.*3d() a lot).

crys.py
-------
* All *3d() funcs use simple loops currently. This is slow. Find vectorized
  versions or re-implement in Fortran (flib.f90) / Cython. But use profiling
  first! Ipython's %prun or kernprof.py / line profiler.
* Structure / Trajectory: Instead of cryst_const, store abc+angles, apply
  length unit to abc and derive cell + cryst_const from abc+angles. 
* rpdf(): Use scipy.spatial.distance.pdist() or cdist() or a variant of
   _flib.distsq_frac() for 3d array which is *much* faster.
  pdist() also returns a "condensed" 1d array w/ all distances. We can feed
  that directly to histogram()! This would solve major problems with that
  fuction.
* rpdf(): If we re-code the distance part in Fortran, add support for variable
  cell trajectories. 
* Maybe make crys.Structure / Trajectory do lazy evaluation by default 
  by setting set_all_auto to False (maybe rename it to "lazy"). No we have:
    st = Structure(...)
    st.cell         # access pre-calculated attr
    st.get_cell()   # calculate and return or return pre-calculated attr
  We want:  
    st.cell # call self.get_cell() if not calculated etc.
  This can be done only if we turn all attrs into lazy evaluated properties.

pydos.py
--------
* let *_pdos() return one 2d arry with several columns, like crys.rpdf()

all
---
* Drop verbose.py. Use the logging or warnings module.
* rename all functions foo3d() -> foo_traj(). But not funcs which take 3d arrays
  directly. Only those which take a Trajectory as argument.


cmd line tools in bin/
----------------------
* We now have abi2axsf.py and cpmd2axsf.py, where the latter is capable of
  doing more nice things like buildung a supercell of the trajectory. If we
  need this machinery for pw.x output too, then it's time to write pwo2axsf.py
  as a replacement for xcrysden's pwo2xsf.sh . Maybe unify all into smth like 
  any2axsf.py. However, whith the new API, we may not need that anymore. Just
  use smth like
    >>> traj = parse.SomeMDParser(...).get_traj()
    >>> sc = crys.scell3d(traj, (3,3,3))
    >>> io.write_axsf('foo_3x3x3.axsf', sc)
  So all these tools can be removed.

tests
-----
* Handle known fails with nose.
* In all test/test_*.py files, rename function test() -> test_<something>(), so
  that ``nosetests --exclude='.*<something>.*'`` works. 

plotting dispersions
--------------------
* Finish functions for parsing and plotting dispersions (pwscf.py, kpath.py).
  Remove unused and redundant stuff.

examples
--------
Clean up examples/phonon_dos/pdos_methods.py .

batch.py
--------
* ParameterStudy: Make extending a study on another machine more easy: Change
  calc.db path to be one above calc_<machine> and automatically make links
  calc/0 -> ../calc_<machine>/0 ?? But that is only convenient for extending a
  study on another machine, while writing to the same database b/c we don't
  care on which machine a calc was run. Currently the workaround is to create
  the input for all machines, maybe extend on one machine and manually
  link-merge all into calc/ and copy the most recent calc_<machine>/calc.db
  file to calc/. But it doesn't work if we do one input for multiple machines
  and manually start only a subset on each machine. Hmmm.

constants.py / units in general
-------------------------------
* Maybe change pressure (GPa currently) and time step (fs = 1e-15 sec) units to
  ASE values?? Would probably break a lot of eval scripts. Maybe to ease the
  transition, first introduce apu (atomic pressure unit = GPa, later ASE value
  = eV / Ang**3), atu (atomic time unit = fs, later ASE value = ???) in
  constants.py and use that everywhere instead of assuming GPa and fs.
* The units implementation is a mess. Now, we have UnitsHandler ->
  StructureFileParser -> parse.*OutputFile and default_units in each 
  *OutputFile. This must be simplified. 

# vim:comments=fb\:*
